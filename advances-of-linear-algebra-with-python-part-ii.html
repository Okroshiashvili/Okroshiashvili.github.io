<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Nodar Okroshiashvili" />

        <meta name="description" content="This is the fourth and last post in blog series about linear algebra. Introduction Basics of linear algebra Intermediate linear algebra Advances in linear algebra: Part I and Part II This is the continuation of the part one and in this post I will introduce you the following topics: Matrix Decompositions Cholesky Decomposition QR Decomposition Eigendecomposition Singular Value Decomposition Inverse of a Square Full Rank Matrix
" />
        <meta name="twitter:creator" content="@N_Okroshiashvil">
        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Linear Algebra, Python, Numpy, Scipy, Mathematics, Mathematics, " />

<meta property="og:title" content="Advances of Linear Algebra with Python - Part II "/>
<meta property="og:url" content="https://dsfabric.org/advances-of-linear-algebra-with-python-part-ii" />
<meta property="og:description" content="This is the fourth and last post in blog series about linear algebra. Introduction Basics of linear algebra Intermediate linear algebra Advances in linear algebra: Part I and Part II This is the continuation of the part one and in this post I will introduce you the following topics: Matrix Decompositions Cholesky Decomposition QR Decomposition Eigendecomposition Singular Value Decomposition Inverse of a Square Full Rank Matrix" />
<meta property="og:site_name" content="Data Science Fabric" />
<meta property="og:article:author" content="Nodar Okroshiashvili" />
<meta property="og:article:published_time" content="2019-03-05T12:14:00+04:00" />
<meta name="twitter:title" content="Advances of Linear Algebra with Python - Part II ">
<meta name="twitter:description" content="This is the fourth and last post in blog series about linear algebra. Introduction Basics of linear algebra Intermediate linear algebra Advances in linear algebra: Part I and Part II This is the continuation of the part one and in this post I will introduce you the following topics: Matrix Decompositions Cholesky Decomposition QR Decomposition Eigendecomposition Singular Value Decomposition Inverse of a Square Full Rank Matrix">

        <title>Advances of Linear Algebra with Python - Part II  · Data Science Fabric
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="https://dsfabric.org/theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://dsfabric.org/theme/tipuesearch/tipuesearch.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://dsfabric.org/theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://dsfabric.org/theme/css/admonition.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://dsfabric.org/theme/css/custom.css" media="screen">

        <link rel="shortcut icon" href="https://dsfabric.org/theme/images/favicon.ico" type="image/x-icon" />
        <link rel="icon" href="https://dsfabric.org/theme/images/apple-touch-icon-152x152.png" type="image/png" />
        <link rel="apple-touch-icon" href="https://dsfabric.org/theme/images/apple-touch-icon.png"  type="image/png" />
        <link rel="apple-touch-icon" sizes="57x57" href="https://dsfabric.org/theme/images/apple-touch-icon-57x57.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="72x72" href="https://dsfabric.org/theme/images/apple-touch-icon-72x72.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="76x76" href="https://dsfabric.org/theme/images/apple-touch-icon-76x76.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="114x114" href="https://dsfabric.org/theme/images/apple-touch-icon-114x114.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="120x120" href="https://dsfabric.org/theme/images/apple-touch-icon-120x120.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="144x144" href="https://dsfabric.org/theme/images/apple-touch-icon-144x144.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="152x152" href="https://dsfabric.org/theme/images/apple-touch-icon-152x152.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="152x152" href="https://dsfabric.org/theme/images/apple-touch-icon-180x180.png" type="image/png" />
        <link href="https://dsfabric.org/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Data Science Fabric - Full Atom Feed" />
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
     (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
     m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
     })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-136307659-1', 'auto');
    ga('send', 'pageview');
</script>


    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://dsfabric.org/"><span class=site-name>Data Science Fabric</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://dsfabric.org
                                    >Home</a>
                                </li>
                                <li ><a href="https://dsfabric.org/categories">Categories</a></li>
                                <li ><a href="https://dsfabric.org/tags">Tags</a></li>
                                <li ><a href="https://dsfabric.org/archives">Archives</a></li>
                                <li><form class="navbar-search" action="https://dsfabric.org/search" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://dsfabric.org/advances-of-linear-algebra-with-python-part-ii">
                Advances of Linear Algebra with Python - Part <span class="caps">II</span>
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is the fourth and last post in blog series about linear&nbsp;algebra.</p>
<ol>
<li>Introduction</li>
<li>Basics of linear&nbsp;algebra</li>
<li>Intermediate linear&nbsp;algebra</li>
<li><strong>Advances in linear algebra</strong>: Part I and <strong>Part <span class="caps">II</span></strong></li>
</ol>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is the continuation of the part one and in this post I will introduce you the following&nbsp;topics:</p>
<ul>
<li><a href="#Matrix_Decompositions">Matrix Decompositions</a><ul>
<li><a href="#Cholesky_Decomposition">Cholesky&nbsp;Decomposition</a></li>
<li><a href="#QR_Decomposition"><span class="caps">QR</span>&nbsp;Decomposition</a></li>
<li><a href="#Eigendecomposition">Eigendecomposition</a></li>
<li><a href="#Singular_Value_Decomposition">Singular Value&nbsp;Decomposition</a></li>
<li><a href="#Inverse_of_a_Square_Full_Rank_Matrix">Inverse of a Square Full Rank&nbsp;Matrix</a></li>
<li><a href="#Numerical_Representation_Decompositions">Numerical&nbsp;Representation</a></li>
</ul>
</li>
<li><a href="#Conclusion">Conclusion</a></li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Matrix-Decompositions">Matrix Decompositions<a class="anchor-link" href="#Matrix-Decompositions">¶</a></h2><p><a id="Matrix_Decompositions"></a></p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In linear algebra, matrix decomposition or matrix factorization is a factorization of a matrix into a product of matrices. Factorizing a matrix means that we want to find a product of matrices that is equal to the initial matrix. These techniques have a wide variety of uses and consequently, there exist several types of decompositions. Below, I will consider some of them, mostly applicable to machine learning or deep&nbsp;learning.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Cholesky-Decomposition">Cholesky Decomposition<a class="anchor-link" href="#Cholesky-Decomposition">¶</a></h3><p><a id="Cholesky_Decomposition"></a></p>
<hr />
<p>The Cholesky Decomposition is the factorization of a given <strong>symmetric</strong> square matrix $A$ into the product of a lower triangular matrix, denoted by $L$ and its transpose $L^{T}$. This decomposition is named after French artillery officer <a href="https://en.wikipedia.org/wiki/Andr%C3%A9-Louis_Cholesky">Andre-Louis Cholesky</a>. The formula&nbsp;is:</p>
\begin{align*}A =
<span class="caps">LL</span>^{T}
\end{align*}<p>For rough sense, let $A$&nbsp;be</p>
\begin{align}A =
\begin{bmatrix}
a_{11} <span class="amp">&amp;</span> a_{12} <span class="amp">&amp;</span> a_{13} &#92;
a_{21} <span class="amp">&amp;</span> a_{22} <span class="amp">&amp;</span> a_{23} &#92;
a_{31} <span class="amp">&amp;</span> a_{32} <span class="amp">&amp;</span> a_{33}
\end{bmatrix}
\end{align}<p>Then we can represent $A$&nbsp;as</p>
\begin{align*}A = <span class="caps">LL</span>^{T} =
\begin{bmatrix}
l_{11} <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> 0 &#92;
l_{21} <span class="amp">&amp;</span> l_{22} <span class="amp">&amp;</span> 0 &#92;
l_{31} <span class="amp">&amp;</span> l_{32} <span class="amp">&amp;</span> l_{33}
\end{bmatrix}
\cdot
\begin{bmatrix}
l_{11} <span class="amp">&amp;</span> l_{12} <span class="amp">&amp;</span> l_{13} &#92;
0 <span class="amp">&amp;</span> l_{22} <span class="amp">&amp;</span> l_{23} &#92;
0 <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> a_{33}
\end{bmatrix} =
\begin{bmatrix}
l_{11}^{2} <span class="amp">&amp;</span> l_{21}l_{11} <span class="amp">&amp;</span> l_{31}l_{11} &#92;
l_{21}l_{11} <span class="amp">&amp;</span> l_{21}^{2} + l_{22}^{2} <span class="amp">&amp;</span> l_{31}l_{21} + l_{32}l_{22} &#92;
l_{31}l_{11} <span class="amp">&amp;</span> l_{31}l_{21} + l_{32}l_{22} <span class="amp">&amp;</span> l_{31}^{2} + l_{32}^{2} + l_{33}^2
\end{bmatrix}
\end{align*}<p>The diagonal elements of matrix $L$ can be calculated by the following&nbsp;formulas:</p>
\begin{align*}
l_{11} = \sqrt{a_{11}}
\quad \quad
l_{22} = \sqrt{a_{22} - l_{21}^{2}}
\quad \quad
l_{33} = \sqrt{a_{33} - (l_{31}^{2} + l_{32}{2})}
\end{align*}<p>And in general, for diagonal elements of the matrix $L$ we&nbsp;have:</p>
\begin{align*}l_{kk} =
\sqrt{a_{kk} - \sum_{j = 1}^{k - 1}l_{kj}^{2}}
\end{align*}<p>For the elements below the main diagonal, $l_{ik}$ where $i > k$, the formulas&nbsp;are</p>
\begin{align*}
l_{21} = \frac{1}{l_{11}}a_{21}
\quad \quad
l_{31} = \frac{1}{l_{11}}a_{31}
\quad \quad
l_{32} = \frac{1}{l_{22}}(a_{32} - l_{31}l_{21})
\end{align*}<p>And the general formula&nbsp;is</p>
\begin{align*}l_{ik} =
\frac{1}{l_{kk}}\Big(a_{ik} - \sum_{j = 1}^{k - 1}l_{ij}l_{kj}\Big)
\end{align*}<p>Messy formulas! Consider a numerical example to see what happen under the hood. We have a matrix&nbsp;$A$</p>
\begin{align*}A =
\begin{bmatrix}
25 <span class="amp">&amp;</span> 15 <span class="amp">&amp;</span> -5 &#92;
15 <span class="amp">&amp;</span> 18 <span class="amp">&amp;</span> 0 &#92;
-5 <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> 11
\end{bmatrix}
\end{align*}<p>According to the above formulas, let find a lower triangular matrix $L$. We&nbsp;have</p>
\begin{align*}
l_{11} = \sqrt{a_{11}} = \sqrt{25} = 5
\quad \quad
l_{22} = \sqrt{a_{22} - l_{21}^{2}} = \sqrt{18 - 3^{2}} = 3
\quad \quad
l_{33} = \sqrt{a_{33} - (l_{31}^{2} + l_{32}^{2})} = \sqrt{11 - ((-1)^{2} + 1^{2})} = 3
\end{align*}<p>Seems, we have missing non-diagonal elements, which&nbsp;are</p>
\begin{align*}
l_{21} = \frac{1}{l_{11}}a_{21} = \frac{1}{5}15 = 3
\quad \quad
l_{31} = \frac{1}{l_{11}}a_{31} = \frac{1}{5}(-5) = -1
\quad \quad
l_{32} = \frac{1}{l_{22}}(a_{32} - l_{31}l_{21}) = \frac{1}{3}(0 - (-1)\cdot 3) = 1
\end{align*}<p>So, our matrix $L$&nbsp;is</p>
\begin{align*}L =
\begin{bmatrix}
5 <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> 0 &#92;
3 <span class="amp">&amp;</span> 3 <span class="amp">&amp;</span> 0 &#92;
-1 <span class="amp">&amp;</span> 1 <span class="amp">&amp;</span> 3
\end{bmatrix}
\quad \quad
L^{T} =
\begin{bmatrix}
5 <span class="amp">&amp;</span> 3 <span class="amp">&amp;</span> -1 &#92;
0 <span class="amp">&amp;</span> 3 <span class="amp">&amp;</span> 1 &#92;
0 <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> 3
\end{bmatrix}
\end{align*}<p>Multiplication of this matrices is up to&nbsp;you.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="QR-Decomposition"><span class="caps">QR</span> Decomposition<a class="anchor-link" href="#QR-Decomposition">¶</a></h3><p><a id="QR_Decomposition"></a></p>
<hr />
<p><span class="caps">QR</span> decomposition is another type of matrix factorization, where a given $m \times n$ matrix $A$ is decomposed into two matrices, $Q$ which is orthogonal matrix, which in turn means that $<span class="caps">QQ</span>^{T} = Q^{T}Q = I$ and the inverse of $Q$ equal to its transpose, $Q^{T} = Q^{-1}$, and $R$ which is upper triangular matrix. Hence, the formula is given&nbsp;by</p>
\begin{align*}A = 
<span class="caps">QR</span>
\end{align*}<p>As $Q$ is an orthogonal matrix, there are three methods to find $Q$, one is <a href="https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process">Gramm-Schmidt Process</a>, second is <a href="https://en.wikipedia.org/wiki/Householder_transformation">Householder Transformation</a>, and third is <a href="https://en.wikipedia.org/wiki/Givens_rotation">Givens Rotation</a>. These methods are out of the scope of this blog post series and hence I&#8217;m going to explain all of them in separate blog posts. Consequently, there is no calculation besides python code in numerical representation&nbsp;section.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Eigendecomposition">Eigendecomposition<a class="anchor-link" href="#Eigendecomposition">¶</a></h3><p><a id="Eigendecomposition"></a></p>
<hr />
<p>Here is the question. What&#8217;s the usage of eigenvalues and eigenvectors? Besides other usages, they help us to perform matrix decomposition and this decomposition is called eigendecomposition or spectral decomposition. In the case of the eigendecomposition, we decompose the initial matrix into the product of its eigenvectors and eigenvalues by the following&nbsp;formula:</p>
\begin{align*}
A = Q \Lambda Q^{-1}
\end{align*}<p>$A$ is $n\times n$ square matrix, $Q$ is the matrix whose columns are the eigenvectors, which in turn are linearly independent and $\Lambda$ is diagonal matrix of eigenvalues of $A$ and these eigenvalues are not necessarily&nbsp;distinct.</p>
<p>To see the detailed steps of this decomposition, consider the abovementioned example of the matrix $A$ for which we already found eigenvalues and&nbsp;eigenvectors.</p>
\begin{align*}A =
\begin{bmatrix}
2 <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> 0 &#92;
0 <span class="amp">&amp;</span> 3 <span class="amp">&amp;</span> 4 &#92;
0 <span class="amp">&amp;</span> 4 <span class="amp">&amp;</span> 9
\end{bmatrix}
\quad
Q =
\begin{bmatrix}
0 <span class="amp">&amp;</span> 1 <span class="amp">&amp;</span> 0 &#92;
-2 <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> 1 &#92;
1 <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> 2
\end{bmatrix}
\quad
\Lambda = 
\begin{bmatrix}
1 <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> 0 &#92;
0 <span class="amp">&amp;</span> 2 <span class="amp">&amp;</span> 0 &#92;
0 <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> 11
\end{bmatrix}
\quad
Q^{-1} =
\begin{bmatrix}
0 <span class="amp">&amp;</span> -0.4 <span class="amp">&amp;</span> 0.2 &#92;
1 <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> 0 &#92;
0 <span class="amp">&amp;</span> 0.2 <span class="amp">&amp;</span> 0.4
\end{bmatrix}
\end{align*}<p>We have all the matrices and now take matrix multiplication according to the above formula. Particularly, multiply $Q$ by $\Lambda$ and by $Q^{-1}$. We have to get original matrix&nbsp;$A$</p>
<p>Furthermore, if matrix $A$ is a real symmetric matrix, then eigendecomposition can be performed by the following&nbsp;formula:</p>
\begin{align*}
A = Q \Lambda Q^{T}
\end{align*}<p>The only difference between this formula and above formula is that the matrix $A$ is $n\times n$ real symmetric square matrix and instead of taking the inverse of eigenvector matrix we take the transpose of it. Moreover, for a real symmetric matrix, eigenvectors corresponding to different eigenvalues are orthogonal. Consider the following&nbsp;example:</p>
\begin{align*}A =
\begin{bmatrix}
6 <span class="amp">&amp;</span> 2 &#92;
2 <span class="amp">&amp;</span> 3
\end{bmatrix}
\end{align*}<p>The matrix is symmetric because of the original matrix equal to its transpose, $A =&nbsp;A^{T}$</p>
<p>Its eigenvalues are $\lambda_{1} = 7$ and $\lambda_{2} = 2$ and corresponding eigenvectors&nbsp;are</p>
\begin{align*}v_{\lambda_{1}} =
\begin{bmatrix}
0.89442719 &#92;
0.4472136
\end{bmatrix}
\quad
v_{\lambda_{2}} =
\begin{bmatrix}
-0.4472136 &#92;
0.89442719
\end{bmatrix}
\end{align*}<p>And in this set up, matrices $Q$, $\Lambda$ and $Q^{T}$ are the&nbsp;following:</p>
\begin{align*}Q =
\begin{bmatrix}
0.89442719 <span class="amp">&amp;</span> -0.4472136 &#92;
0.4472136 <span class="amp">&amp;</span> 0.89442719 &#92;
\end{bmatrix}
\quad
\Lambda = 
\begin{bmatrix}
7 <span class="amp">&amp;</span> 0 &#92;
0 <span class="amp">&amp;</span> 2 &#92;
\end{bmatrix}
\quad
Q^{T} =
\begin{bmatrix}
0.89442719 <span class="amp">&amp;</span> 0.4472136 &#92;
-0.4472136 <span class="amp">&amp;</span> 0.89442719 &#92;
\end{bmatrix}
\end{align*}<p>Taking matrix product gives initial matrix&nbsp;$A$.</p>
<p>To verify all of this calculation see Python code&nbsp;below.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Eigendecomposition cannot be used for nonsquare matrices. Below, we will see the Singular Value Decomposition (<span class="caps">SVD</span>) which is another way of decomposing matrices. The advantage of the <span class="caps">SVD</span> is that you can use it also with non-square&nbsp;matrices.</strong></p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Singular-Value-Decomposition">Singular Value Decomposition<a class="anchor-link" href="#Singular-Value-Decomposition">¶</a></h3><p><a id="Singular_Value_Decomposition"></a></p>
<hr />
<p>Singular Value Decomposition (<span class="caps">SVD</span>) is another way of matrix factorization. It is the generalization of the eigendecomposition. In this context, generalization means that eigendecomposition is applicable only for square $n \times n$ matrices, while Singular Value Decomposition (<span class="caps">SVD</span>) is applicable for any $m \times n$&nbsp;matrices.</p>
<p><span class="caps">SVD</span> for a $m \times n$ matrix $A$ is computed by the following&nbsp;formula:</p>
\begin{align*}
A = U \ D \ V^{T}
\end{align*}<p>Where, $U$&#8217;s columns are <em>left singular vectors</em> of $A$, $V$&#8217;s columns are <em>right singular vectors</em> of $A$ and $D$  is a diagonal matrix, not necessarily square matrix, containing <strong>singular values</strong> of $A$ on main diagonal. Singular values of $m \times n$ matrix $A$ are the <strong>square roots of the eigenvalues</strong> of $A^{T}A$, which is a square matrix. If our initial matrix $A$ is square or $n \times n$ then singular values <strong>coincide</strong> eigenvalues. Moreover, all of these defines the path towards eigendecomposition. Let see how this path is&nbsp;defined.</p>
<p>Matrices, $U$, $D$, and $V$ can be found by transforming $A$ into a square matrix and computing eigenvalues and eigenvectors of this transformed matrix. This transformation is done by multiplying $A$ by its transpose $A^{T}$. After that, matrices $U$, $D$ and $V$ are the&nbsp;following:</p>
<ul>
<li><p>$U$ corresponds to the eigenvectors of $<span class="caps">AA</span>^{T}$</p>
</li>
<li><p>$V$ corresponds to eigenvectors of&nbsp;$A^{T}A$</p>
</li>
<li><p>$D$ corresponds to eigenvalues, either $<span class="caps">AA</span>^{T}$ or $A^{T}A$, which are the&nbsp;same</p>
</li>
</ul>
<p>Theory almost always seems confusing. Consider a numerical example and Python code below for&nbsp;clarification.</p>
<p>Let our initial matrix $A$&nbsp;be:</p>
\begin{align*}A =
\begin{bmatrix}
0 <span class="amp">&amp;</span> 1 <span class="amp">&amp;</span> 0 &#92;
\sqrt{2} <span class="amp">&amp;</span> 2 <span class="amp">&amp;</span> 0 &#92;
0 <span class="amp">&amp;</span> 1 <span class="amp">&amp;</span> 1
\end{bmatrix}
\end{align*}<p>Here, to use <span class="caps">SVD</span> first we need to find $<span class="caps">AA</span>^{T}$ and&nbsp;$A^{T}A$.</p>
\begin{align*}<span class="caps">AA</span>^{T} =
\begin{bmatrix}
2 <span class="amp">&amp;</span> 2 <span class="amp">&amp;</span> 2 &#92;
2 <span class="amp">&amp;</span> 6 <span class="amp">&amp;</span> 2 &#92;
2 <span class="amp">&amp;</span> 2 <span class="amp">&amp;</span> 2
\end{bmatrix}
\quad
A^{T}A =
\begin{bmatrix}
2 <span class="amp">&amp;</span> 2\sqrt{2} <span class="amp">&amp;</span> 0 &#92;
2\sqrt{2} <span class="amp">&amp;</span> 6 <span class="amp">&amp;</span> 2 &#92;
0 <span class="amp">&amp;</span> 2 <span class="amp">&amp;</span> 2
\end{bmatrix}
\end{align*}<p>In the next step, we have to find eigenvalues and eigenvectors for $<span class="caps">AA</span>^{T}$ and $A^{T}A$. The characteristic polynomial&nbsp;is</p>
\begin{align*}
-\lambda^{3} + 10\lambda^2 - 16\lambda
\end{align*}<p>with roots equal to $\lambda_{1} = 8$, $\lambda_{2} = 2$, and $\lambda_{3} = 0$. Note that these eigenvalues are the same for the $A^{T}A$. We need singular values which are square root from eigenvalues. Let denote them by $\sigma$ such as $\sigma_{1} = \sqrt{8} = 2\sqrt{2}$, $\sigma_{2} = \sqrt{2}$ and $\sigma_{3} = \sqrt{0} = 0$. We now can construct diagonal matrix of singular&nbsp;values:</p>
\begin{align*}D =
\begin{bmatrix}
2\sqrt{2} <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> 0 &#92;
0 <span class="amp">&amp;</span> \sqrt{2} <span class="amp">&amp;</span> 0 &#92;
0 <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> 0
\end{bmatrix}
\end{align*}<p>Now we have to find matrices $U$ and $V$. We have everything what we need. First find eigenvectors of $<span class="caps">AA</span>^{T}$ for $\lambda_{1} = 8$, $\lambda_{2} = 2$, and $\lambda_{3} = 0$, which are the&nbsp;following:</p>
\begin{align*}U_{1} =
\begin{bmatrix}
\frac{1}{\sqrt{6}}&#92;
\frac{2}{\sqrt{6}} &#92;
\frac{1}{\sqrt{6}}
\end{bmatrix}
\quad
U_{2} =
\begin{bmatrix}
-\frac{1}{\sqrt{3}}&#92;
\frac{1}{\sqrt{3}} &#92;
-\frac{1}{\sqrt{3}}
\end{bmatrix}
\quad
U_{3} =
\begin{bmatrix}
\frac{1}{\sqrt{2}}&#92;
0 &#92;
-\frac{1}{\sqrt{2}}
\end{bmatrix}
\end{align*}<p>Note that eigenvectors are&nbsp;normilized.</p>
<p>As we have eigenvectors, our $U$ matrix&nbsp;is:</p>
\begin{align*}U =
\begin{bmatrix}
\frac{1}{\sqrt{6}} <span class="amp">&amp;</span> -\frac{1}{\sqrt{3}} <span class="amp">&amp;</span> \frac{1}{\sqrt{2}}&#92;
\frac{2}{\sqrt{6}} <span class="amp">&amp;</span> \frac{1}{\sqrt{3}} <span class="amp">&amp;</span> 0 &#92;
\frac{1}{\sqrt{6}} <span class="amp">&amp;</span> -\frac{1}{\sqrt{3}} <span class="amp">&amp;</span> -\frac{1}{\sqrt{2}}
\end{bmatrix}
\end{align*}<p>In the same fashin, we can find matrix $V$, which&nbsp;is:</p>
\begin{align*}V =
\begin{bmatrix}
\frac{1}{\sqrt{6}} <span class="amp">&amp;</span> \frac{1}{\sqrt{3}} <span class="amp">&amp;</span> \frac{1}{\sqrt{2}}&#92;
\frac{3}{\sqrt{12}} <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> -\frac{1}{2} &#92;
\frac{1}{\sqrt{12}} <span class="amp">&amp;</span> -\frac{2}{\sqrt{6}} <span class="amp">&amp;</span> \frac{1}{2}
\end{bmatrix}
\end{align*}<p>According to the formula we&nbsp;have</p>
\begin{align*}
A = U \ D \ V^{T} =
\begin{bmatrix}
\frac{1}{\sqrt{6}} <span class="amp">&amp;</span> -\frac{1}{\sqrt{3}} <span class="amp">&amp;</span> \frac{1}{\sqrt{2}}&#92;
\frac{2}{\sqrt{6}} <span class="amp">&amp;</span> \frac{1}{\sqrt{3}} <span class="amp">&amp;</span> 0 &#92;
\frac{1}{\sqrt{6}} <span class="amp">&amp;</span> -\frac{1}{\sqrt{3}} <span class="amp">&amp;</span> -\frac{1}{\sqrt{2}}
\end{bmatrix}
\cdot
\begin{bmatrix}
2\sqrt{2} <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> 0 &#92;
0 <span class="amp">&amp;</span> \sqrt{2} <span class="amp">&amp;</span> 0 &#92;
0 <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> 0
\end{bmatrix}
\cdot
\begin{bmatrix}
\frac{1}{\sqrt{6}} <span class="amp">&amp;</span> \frac{1}{\sqrt{3}} <span class="amp">&amp;</span> \frac{1}{\sqrt{2}}&#92;
\frac{3}{\sqrt{12}} <span class="amp">&amp;</span> 0 <span class="amp">&amp;</span> -\frac{1}{2} &#92;
\frac{1}{\sqrt{12}} <span class="amp">&amp;</span> -\frac{2}{\sqrt{6}} <span class="amp">&amp;</span> \frac{1}{2}
\end{bmatrix}
^{T} = A
\end{align*}
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Inverse-of-a-Square-Full-Rank-Matrix">Inverse of a Square Full Rank Matrix<a class="anchor-link" href="#Inverse-of-a-Square-Full-Rank-Matrix">¶</a></h3><p><a id="Inverse_of_a_Square_Full_Rank_Matrix"></a></p>
<hr />
<p>Here, I want to present one more way to find the inverse of a matrix and show you one more usage of eigendecomposition. Let&#8217;s get started. If a matrix $A$ can be eigendecomposed and it has no any eigenvalue equal to zero, then this matrix has the inverse and this inverse is given&nbsp;by:</p>
\begin{align*}A^{-1} =
Q \Lambda^{-1} Q^{-1}
\end{align*}<p>Matrices, $Q$, and $\Lambda$ are already known for us. Consider an&nbsp;example:</p>
\begin{align*}A =
\begin{bmatrix}
1 <span class="amp">&amp;</span> 2 &#92;
4 <span class="amp">&amp;</span> 3
\end{bmatrix}
\end{align*}<p>Its eigenvalues are $\lambda_{1} = -1$ and $\lambda_{2} = 5$ and eigenvectors&nbsp;are:</p>
\begin{align*}v_{\lambda_{1}} =
\begin{bmatrix}
-0.70710678 &#92;
0.70710678
\end{bmatrix}
\quad
v_{\lambda_{2}} =
\begin{bmatrix}
0.4472136 &#92;
-0.89442719
\end{bmatrix}
\end{align*}<p>Let calculate the onverse of&nbsp;$A$</p>
\begin{align*}A^{-1} = Q \Lambda^{-1} Q^{-1} =
\begin{bmatrix}
-0.70710678 <span class="amp">&amp;</span> -0.4472136 &#92;
0.70710678 <span class="amp">&amp;</span> -0.89442719
\end{bmatrix}
\cdot
\begin{bmatrix}
-1 <span class="amp">&amp;</span> -0 &#92;
0 <span class="amp">&amp;</span> 0.2
\end{bmatrix}
\cdot
\begin{bmatrix}
-0.94280904 <span class="amp">&amp;</span> 0.47140452 &#92;
-0.74535599 <span class="amp">&amp;</span> -0.74535599
\end{bmatrix} =
\begin{bmatrix}
-0.6 <span class="amp">&amp;</span> 0.4 &#92;
0.8 <span class="amp">&amp;</span> -0.2
\end{bmatrix}
\end{align*}
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Numerical-Representation">Numerical Representation<a class="anchor-link" href="#Numerical-Representation">¶</a></h3><p><a id="Numerical_Representation_Decompositions"></a></p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Cholesky-Decomposition">Cholesky Decomposition<a class="anchor-link" href="#Cholesky-Decomposition">¶</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">25</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="o">-</span><span class="mi">5</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">15</span><span class="p">,</span><span class="mi">18</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
              <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">11</span><span class="p">]])</span>


<span class="c1"># Cholesky decomposition, find lower triangular matrix L</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="c1"># Take transpose</span>
<span class="n">L_T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>


<span class="c1"># Check if it's correct</span>
<span class="n">A</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">L_T</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt output_prompt">Out[1]:</div>
<div class="output_text output_subarea output_execute_result">
<pre>array([[ True,  True,  True],
       [ True,  True,  True],
       [ True,  True,  True]])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="QR-Decomposition"><span class="caps">QR</span> Decomposition<a class="anchor-link" href="#QR-Decomposition">¶</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">12</span><span class="p">,</span><span class="o">-</span><span class="mi">51</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="mi">167</span><span class="p">,</span><span class="o">-</span><span class="mi">68</span><span class="p">],</span>
              <span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="o">-</span><span class="mi">41</span><span class="p">]])</span>


<span class="c1"># QR decomposition</span>
<span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">"Q ="</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"R ="</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"A = QR"</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span><span class="n">R</span><span class="p">),</span> <span class="n">sep</span><span class="o">=</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Q =
[[-0.85714286  0.39428571  0.33142857]
 [-0.42857143 -0.90285714 -0.03428571]
 [ 0.28571429 -0.17142857  0.94285714]]

R =
[[ -14.  -21.   14.]
 [   0. -175.   70.]
 [   0.    0.  -35.]]

A = QR
[[ 12. -51.   4.]
 [  6. 167. -68.]
 [ -4.  24. -41.]]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Eigendecomposition">Eigendecomposition<a class="anchor-link" href="#Eigendecomposition">¶</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="c1"># Eigendecomposition for nonsymmetric matrix</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">9</span><span class="p">]])</span>


<span class="n">eigenvalues1</span><span class="p">,</span> <span class="n">eigenvectors1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>


<span class="c1"># Form diagonal matrix from eigenvalues</span>
<span class="n">L1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">eigenvalues1</span><span class="p">)</span>


<span class="c1"># Seperate eigenvector matrix and take its inverse</span>
<span class="n">Q1</span> <span class="o">=</span> <span class="n">eigenvectors1</span>
<span class="n">inv_Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Q1</span><span class="p">)</span>


<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q1</span><span class="p">,</span><span class="n">L1</span><span class="p">),</span><span class="n">inv_Q</span><span class="p">)</span>


<span class="c1"># Check if B equal to A</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Decomposed matrix B:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>


<span class="c1"># Numpy produces normilized eigenvectors and don't be confused with my calculations above</span>




<span class="c1"># Eigendecomposition for symmetric matrix</span>

<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">6</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]])</span>

<span class="n">eigenvalues2</span><span class="p">,</span> <span class="n">eigenvectors2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>

<span class="c1"># Eigenvalues</span>
<span class="n">L2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">eigenvalues2</span><span class="p">)</span>

<span class="c1"># Eigenvectors</span>
<span class="n">Q2</span> <span class="o">=</span> <span class="n">eigenvectors2</span>
<span class="n">Q2_T</span> <span class="o">=</span> <span class="n">Q2</span><span class="o">.</span><span class="n">T</span>


<span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q2</span><span class="p">,</span><span class="n">L2</span><span class="p">),</span><span class="n">Q2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>


<span class="c1"># Check if D equal to C</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Decomposed matrix D:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Decomposed matrix B:
[[2. 0. 0.]
 [0. 3. 4.]
 [0. 4. 9.]]

Decomposed matrix D:
[[6. 2.]
 [2. 3.]]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Singular-Value-Decomposition">Singular Value Decomposition<a class="anchor-link" href="#Singular-Value-Decomposition">¶</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># Suppres scientific notation</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
              <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>


<span class="n">U</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"U ="</span><span class="p">,</span> <span class="n">U</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"D ="</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"V ="</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>

<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">D</span><span class="p">),</span> <span class="n">V</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"B ="</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>U = [[-0.32099833  0.14524317 -0.93587632]
 [-0.87192053 -0.43111301  0.23215547]
 [-0.36974946  0.8905313   0.26502706]]

D = [2.75398408 1.09310654 0.46977627]

V = [[-0.44774472 -0.8840243  -0.13425984]
 [-0.55775521  0.15876626  0.81467932]
 [ 0.69888038 -0.43965249  0.56415592]]

B = [[ 0.          1.         -0.        ]
 [ 1.41421356  2.          0.        ]
 [ 0.          1.          1.        ]]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Inverse-of-a-Square-Full-Rank-Matrix">Inverse of a Square Full Rank Matrix<a class="anchor-link" href="#Inverse-of-a-Square-Full-Rank-Matrix">¶</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">]])</span>


<span class="c1"># Eigenvalues and Eigenvectors</span>
<span class="n">L</span><span class="p">,</span> <span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="c1"># Diagonal eigenvalues</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
<span class="c1"># Inverse</span>
<span class="n">inv_L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>

<span class="c1"># Inverse of igenvector matrix</span>
<span class="n">inv_Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>


<span class="c1"># Calculate the inverse of A</span>
<span class="n">inv_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">inv_L</span><span class="p">,</span><span class="n">inv_Q</span><span class="p">))</span>

<span class="c1"># Print the inverse</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"The inverse of A is"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inv_A</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>The inverse of A is
[[-0.6  0.4]
 [ 0.8 -0.2]]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion">¶</a></h2><p><a id="Conclusion"></a></p>
<hr />
<p>In conclusion, my aim was to make linear algebra tutorials which are in absence, while learning machine learning or deep learning. Particularly, existing materials either are pure mathematics books which cover lots of unnecessary(actually they are necessary) things or machine learning books which assume that you already have some linear algebra knowledge. The series starts from very basic and at the end explains some advanced topics. I can say that I tried my best to filter the materials and only explained the most relevant linear algebra topics for machine learning and deep&nbsp;learning.</p>
<p>Based on my experience, these tutorials are not enough to master the concepts and all intuitions but the journey should be continuous. Meaning, that you have to practice more and&nbsp;more.</p>
<p>Now, I realize that, for aspiring data scientists, besides my hard work, some topic may not be still clear. For that don&#8217;t hesitate and comment&nbsp;below.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="References">References<a class="anchor-link" href="#References">¶</a></h3><p><a id="References"></a></p>
<h4 id="Matrix-Decomposition">Matrix Decomposition<a class="anchor-link" href="#Matrix-Decomposition">¶</a></h4><ul>
<li><p><a href="https://rosettacode.org/wiki/Cholesky_decomposition">Cholesky&nbsp;Decomposition</a></p>
</li>
<li><p><a href="https://en.wikipedia.org/wiki/Matrix_decomposition">Matrix&nbsp;Decomposition</a></p>
</li>
<li><p><a href="http://math.mit.edu/~gs/linearalgebra/">Introduction To Linear&nbsp;Algebra</a></p>
</li>
</ul>
</div>
</div>
</div>

<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>



                <p id="post-share-links">
    Like this post? Share on:
    <a href="https://twitter.com/intent/tweet?text=Advances%20of%20Linear%20Algebra%20with%20Python%20-%20Part%20II&url=https%3A//dsfabric.org/advances-of-linear-algebra-with-python-part-ii&via=N_Okroshiashvil&hashtags=linear-algebra,python,numpy,scipy,mathematics" target="_blank" title="Share on Twitter">Twitter</a>
    ❄
    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//dsfabric.org/advances-of-linear-algebra-with-python-part-ii" target="_blank" title="Share on Facebook">Facebook</a>
    ❄
    <a href="mailto:?subject=Advances%20of%20Linear%20Algebra%20with%20Python%20-%20Part%20II&amp;body=https%3A//dsfabric.org/advances-of-linear-algebra-with-python-part-ii" target="_blank" title="Share via Email">Email</a>
    </p>

            
            






<section>
    <h6 style="display:none;">Comments</h6>
    <p id="comment-message">So what do you think? Did I miss something? Is any part unclear? Leave your comments below. </p>

    <div class="accordion" id="accordion2">
        <div class="accordion-group">
            <div class="accordion-heading">
                <a class="accordion-toggle disqus-comment-count comment-count"
                   data-toggle="collapse"
                   data-parent="#accordion2"
                   data-disqus-identifier="https://dsfabric.org/advances-of-linear-algebra-with-python-part-ii"
                   href="https://dsfabric.org/advances-of-linear-algebra-with-python-part-ii#comment_thread"
                   id="comment-accordion-toggle">
                    Comments
                </a>
            </div>
            <div id="comment_thread" class="accordion-body collapse">
                <div class="accordion-inner">
                    <div class="comments">
                        <div id="disqus_thread"></div>
                        <script>
    var disqus_shortname = 'dsfabric';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());

    var disqus_identifier = 'https://dsfabric.org/advances-of-linear-algebra-with-python-part-ii';
    var disqus_url = 'https://dsfabric.org/advances-of-linear-algebra-with-python-part-ii';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>

<noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

            <hr/>
<section>
    <h2>Keep Reading</h2>
<ul class="related-posts-list">
<li><a href="https://dsfabric.org/introduction-to-linear-algebra-with-python" title="Introduction to Linear Algebra with Python">Introduction to Linear Algebra with Python</a></li>
<li><a href="https://dsfabric.org/basics-of-linear-algebra-with-python" title="Basics of Linear Algebra with Python">Basics of Linear Algebra with Python</a></li>
<li><a href="https://dsfabric.org/intermediates-of-linear-algebra-with-python-part-i" title="Intermediates of Linear Algebra with Python - Part I">Intermediates of Linear Algebra with Python - Part I</a></li>
<li><a href="https://dsfabric.org/intermediates-of-linear-algebra-with-python-part-ii" title="Intermediates of Linear Algebra with Python - Part II">Intermediates of Linear Algebra with Python - Part II</a></li>
<li><a href="https://dsfabric.org/advances-of-linear-algebra-with-python-part-i" title="Advances of Linear Algebra with Python - Part I">Advances of Linear Algebra with Python - Part I</a></li>
</ul>
<hr />
</section>
            <aside>
            <nav>
            <ul class="articles-timeline">
                <li class="previous-article">« <a href="https://dsfabric.org/advances-of-linear-algebra-with-python-part-i" title="Previous: Advances of Linear Algebra with Python - Part I">Advances of Linear Algebra with Python - Part I</a></li>
                <li class="next-article"><a href="https://dsfabric.org/python-test" title="Next: Python - Test">Python - Test</a> »</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section>
        <div class="span2" style="float:right;font-size:0.9em;">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2019-03-05T12:14:00+04:00">Mar 5, 2019</time>
            <h4>Category</h4>
            <a class="category-link" href="https://dsfabric.org/categories#mathematics-ref">Mathematics</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://dsfabric.org/tags#linear-algebra-ref">Linear Algebra
                    <span>6</span>
</a></li>
                <li><a href="https://dsfabric.org/tags#numpy-ref">Numpy
                    <span>7</span>
</a></li>
                <li><a href="https://dsfabric.org/tags#python-ref">Python
                    <span>10</span>
</a></li>
                <li><a href="https://dsfabric.org/tags#scipy-ref">Scipy
                    <span>7</span>
</a></li>
                <li><a href="https://dsfabric.org/tags#mathematics-ref">Mathematics
</a></li>
            </ul>
<h4>Stay in Touch</h4>
<div id="sidebar-social-link">
    <a href="https://www.linkedin.com/in/nodar-okroshiashvili/" title="" target="_blank" rel="nofollow">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="LinkedIn" role="img" viewBox="0 0 512 512" fill="#fff"><rect width="512" height="512" rx="15%" fill="#0077b5"/><circle cx="142" cy="138" r="37"/><path stroke="#fff" stroke-width="66" d="M244 194v198M142 194v198"/><path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg>
    </a>
    <a href="https://github.com/Okroshiashvili" title="" target="_blank" rel="nofollow">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
    <a href="https://twitter.com/N_Okroshiashvil" title="" target="_blank" rel="nofollow">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="Twitter" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1da1f3"/><path fill="#fff" d="M437 152a72 72 0 0 1-40 12 72 72 0 0 0 32-40 72 72 0 0 1-45 17 72 72 0 0 0-122 65 200 200 0 0 1-145-74 72 72 0 0 0 22 94 72 72 0 0 1-32-7 72 72 0 0 0 56 69 72 72 0 0 1-32 1 72 72 0 0 0 67 50 200 200 0 0 1-105 29 200 200 0 0 0 309-179 200 200 0 0 0 35-37"/></svg>
    </a>
</div>
            





            





        </div>
        </section>
</div>
</article>
                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>

    <div>
        <span class="site-name">Data Science Fabric</span> - Torture the data, and it will confess to anything. Ronald Coase
    </div>



    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>