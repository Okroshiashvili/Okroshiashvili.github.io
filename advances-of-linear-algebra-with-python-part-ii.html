<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://dsfabric.org/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://dsfabric.org/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="Nodar Okroshiashvili" />

        <meta name="description" content="This is the second part of advance linear algebra with Python
" />
        <meta name="twitter:creator" content="@N_Okroshiashvil">
        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Advance Linear Algebra, Mathematics, Mathematics, advance linear algebra, matrix decompositions in python, linear algebra advances in python, advance linear algebra for machine learning" />

<meta property="og:title" content="Advances of Linear Algebra with Python - Part II "/>
<meta property="og:url" content="https://dsfabric.org/advances-of-linear-algebra-with-python-part-ii" />
<meta property="og:description" content="This is the second part of advance linear algebra with Python" />
<meta property="og:site_name" content="Data Science Fabric" />
<meta property="og:article:author" content="Nodar Okroshiashvili" />
<meta property="og:article:published_time" content="2019-03-05T12:14:00+04:00" />
<meta name="twitter:title" content="Advances of Linear Algebra with Python - Part II ">
<meta name="twitter:description" content="This is the second part of advance linear algebra with Python">

        <title>Advances of Linear Algebra with Python - Part II  Â· Data Science Fabric
</title>
        <link rel="shortcut icon" href="https://dsfabric.org/theme/images/favicon.ico" type="image/x-icon" />
        <link rel="icon" href="https://dsfabric.org/theme/images/apple-touch-icon-152x152.png" type="image/png" />
        <link rel="apple-touch-icon" href="https://dsfabric.org/theme/images/apple-touch-icon.png"  type="image/png" />
        <link rel="apple-touch-icon" sizes="57x57" href="https://dsfabric.org/theme/images/apple-touch-icon-57x57.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="72x72" href="https://dsfabric.org/theme/images/apple-touch-icon-72x72.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="76x76" href="https://dsfabric.org/theme/images/apple-touch-icon-76x76.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="114x114" href="https://dsfabric.org/theme/images/apple-touch-icon-114x114.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="120x120" href="https://dsfabric.org/theme/images/apple-touch-icon-120x120.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="144x144" href="https://dsfabric.org/theme/images/apple-touch-icon-144x144.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="152x152" href="https://dsfabric.org/theme/images/apple-touch-icon-152x152.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="152x152" href="https://dsfabric.org/theme/images/apple-touch-icon-180x180.png" type="image/png" />
        <link href="https://dsfabric.org/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Data Science Fabric - Full Atom Feed" />
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
     (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
     m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
     })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-136307659-1', 'auto');
    ga('send', 'pageview');
</script>


    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://dsfabric.org/"><span class=site-name>Data Science Fabric</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://dsfabric.org
                                    >Home</a>
                                </li>
                                <li ><a href="https://dsfabric.org/categories">Categories</a></li>
                                <li ><a href="https://dsfabric.org/tags">Tags</a></li>
                                <li ><a href="https://dsfabric.org/archives">Archives</a></li>
                                <li><form class="navbar-search" action="https://dsfabric.org/search" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://dsfabric.org/advances-of-linear-algebra-with-python-part-ii">
                Advances of Linear Algebra with Python - Part II
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>This is the fourth and last post in blog series about linear algebra.</p>
<ol>
<li>Introduction</li>
<li>Basics of linear algebra</li>
<li>Intermediate linear algebra</li>
<li><strong>Advances in linear algebra</strong>: Part I and <strong>Part II</strong></li>
</ol>
<p>This is the continuation of the part one and in this post I will introduce you the following topics:</p>
<ul>
<li><a href="#matrix-decompositions">Matrix Decompositions</a></li>
<li><a href="#cholesky-decomposition">Cholesky Decomposition</a></li>
<li><a href="#qr-decomposition">QR Decomposition</a></li>
<li><a href="#eigendecomposition">Eigendecomposition</a></li>
<li><a href="#singular-value-decomposition">Singular Value Decomposition</a></li>
<li><a href="#inverse-of-a-square-full-rank-matrix">Inverse of a Square Full Rank Matrix</a></li>
<li><a href="#numerical-representation">Numerical Representation</a><ul>
<li><a href="#cholesky-decomposition-1">Cholesky Decomposition</a></li>
<li><a href="#qr-decomposition-1">QR Decomposition</a></li>
<li><a href="#eigendecomposition-1">Eigendecomposition</a></li>
<li><a href="#singular-value-decomposition-1">Singular Value Decomposition</a></li>
<li><a href="#inverse-of-a-square-full-rank-matrix-1">Inverse of a Square Full Rank Matrix</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#references">References</a><ul>
<li><a href="#matrix-decomposition">Matrix Decomposition</a></li>
</ul>
</li>
</ul>
<h2 id="matrix-decompositions">Matrix Decompositions<a class="headerlink" href="#matrix-decompositions" title="Permanent link">&para;</a></h2>
<p><a id="Matrix_Decompositions"></a></p>
<p>In linear algebra, matrix decomposition or matrix factorization is a factorization of a matrix into a product of matrices. 
Factorizing a matrix means that we want to find a product of matrices that is equal to the initial matrix. 
These techniques have a wide variety of uses and consequently, there exist several types of decompositions. 
Below, I will consider some of them, mostly applicable to machine learning or deep learning.</p>
<h3 id="cholesky-decomposition">Cholesky Decomposition<a class="headerlink" href="#cholesky-decomposition" title="Permanent link">&para;</a></h3>
<p><a id="Cholesky_Decomposition"></a></p>
<hr>
<p>The Cholesky Decomposition is the factorization of a given <strong>symmetric</strong> square matrix <span class="math">\(A\)</span> into the product of a 
lower triangular matrix, denoted by <span class="math">\(L\)</span> and its transpose <span class="math">\(L^{T}\)</span>. This decomposition is named after French artillery 
officer <a href="https://en.wikipedia.org/wiki/Andr%C3%A9-Louis_Cholesky">Andre-Louis Cholesky</a>. The formula is:</p>
<div class="math">$$
A =
LL^{T}
$$</div>
<p>For rough sense, let <span class="math">\(A\)</span> be</p>
<div class="math">$$
A =
\begin{bmatrix}
a_{11} &amp; a_{12} &amp; a_{13} \\
a_{21} &amp; a_{22} &amp; a_{23} \\
a_{31} &amp; a_{32} &amp; a_{33}
\end{bmatrix}
$$</div>
<p>Then we can represent <span class="math">\(A\)</span> as </p>
<div class="math">$$
A = LL^{T} =
\begin{bmatrix}
l_{11} &amp; 0 &amp; 0 \\
l_{21} &amp; l_{22} &amp; 0 \\
l_{31} &amp; l_{32} &amp; l_{33}
\end{bmatrix}
\cdot
\begin{bmatrix}
l_{11} &amp; l_{12} &amp; l_{13} \\
0 &amp; l_{22} &amp; l_{23} \\
0 &amp; 0 &amp; a_{33}
\end{bmatrix} =
\begin{bmatrix}
l_{11}^{2} &amp; l_{21}l_{11} &amp; l_{31}l_{11} \\
l_{21}l_{11} &amp; l_{21}^{2} + l_{22}^{2} &amp; l_{31}l_{21} + l_{32}l_{22} \\
l_{31}l_{11} &amp; l_{31}l_{21} + l_{32}l_{22} &amp; l_{31}^{2} + l_{32}^{2} + l_{33}^2
\end{bmatrix}
$$</div>
<p>The diagonal elements of matrix <span class="math">\(L\)</span> can be calculated by the following formulas:</p>
<div class="math">$$
l_{11} = \sqrt{a_{11}}
\quad \quad
l_{22} = \sqrt{a_{22} - l_{21}^{2}}
\quad \quad
l_{33} = \sqrt{a_{33} - (l_{31}^{2} + l_{32}{2})}
$$</div>
<p>And in general, for diagonal elements of the matrix <span class="math">\(L\)</span> we have:</p>
<div class="math">$$
l_{kk} =
\sqrt{a_{kk} - \sum_{j = 1}^{k - 1}l_{kj}^{2}}
$$</div>
<p>For the elements below the main diagonal, <span class="math">\(l_{ik}\)</span> where <span class="math">\(i &gt; k\)</span>, the formulas are</p>
<div class="math">$$
l_{21} = \frac{1}{l_{11}}a_{21}
\quad \quad
l_{31} = \frac{1}{l_{11}}a_{31}
\quad \quad
l_{32} = \frac{1}{l_{22}}(a_{32} - l_{31}l_{21})
$$</div>
<p>And the general formula is</p>
<div class="math">$$
l_{ik} =
\frac{1}{l_{kk}}\Big(a_{ik} - \sum_{j = 1}^{k - 1}l_{ij}l_{kj}\Big)
$$</div>
<p>Messy formulas! Consider a numerical example to see what happen under the hood. We have a matrix <span class="math">\(A\)</span></p>
<div class="math">$$
A =
\begin{bmatrix}
25 &amp; 15 &amp; -5 \\
15 &amp; 18 &amp; 0 \\
-5 &amp; 0 &amp; 11
\end{bmatrix}
$$</div>
<p>According to the above formulas, let find a lower triangular matrix <span class="math">\(L\)</span>. We have</p>
<div class="math">$$
l_{11} = \sqrt{a_{11}} = \sqrt{25} = 5
\quad \quad
l_{22} = \sqrt{a_{22} - l_{21}^{2}} = \sqrt{18 - 3^{2}} = 3
\quad \quad
l_{33} = \sqrt{a_{33} - (l_{31}^{2} + l_{32}^{2})} = \sqrt{11 - ((-1)^{2} + 1^{2})} = 3
$$</div>
<p>Seems, we have missing non-diagonal elements, which are</p>
<div class="math">$$
l_{21} = \frac{1}{l_{11}}a_{21} = \frac{1}{5}15 = 3
\quad \quad
l_{31} = \frac{1}{l_{11}}a_{31} = \frac{1}{5}(-5) = -1
\quad \quad
l_{32} = \frac{1}{l_{22}}(a_{32} - l_{31}l_{21}) = \frac{1}{3}(0 - (-1)\cdot 3) = 1
$$</div>
<p>So, our matrix <span class="math">\(L\)</span> is</p>
<div class="math">$$
L =
\begin{bmatrix}
5 &amp; 0 &amp; 0 \\
3 &amp; 3 &amp; 0 \\
-1 &amp; 1 &amp; 3
\end{bmatrix}
\quad \quad
L^{T} =
\begin{bmatrix}
5 &amp; 3 &amp; -1 \\
0 &amp; 3 &amp; 1 \\
0 &amp; 0 &amp; 3
\end{bmatrix}
$$</div>
<p>Multiplication of this matrices is up to you.</p>
<h3 id="qr-decomposition">QR Decomposition<a class="headerlink" href="#qr-decomposition" title="Permanent link">&para;</a></h3>
<p><a id="QR_Decomposition"></a></p>
<hr>
<p>QR decomposition is another type of matrix factorization, where a given <span class="math">\(m \times n\)</span> matrix <span class="math">\(A\)</span> is decomposed into 
two matrices, <span class="math">\(Q\)</span> which is orthogonal matrix, which in turn means that <span class="math">\(QQ^{T} = Q^{T}Q = I\)</span> and the inverse of <span class="math">\(Q\)</span> 
equal to its transpose, <span class="math">\(Q^{T} = Q^{-1}\)</span>, and <span class="math">\(R\)</span> which is upper triangular matrix. Hence, the formula is given by</p>
<div class="math">$$
A = 
QR
$$</div>
<p>As <span class="math">\(Q\)</span> is an orthogonal matrix, there are three methods to find <span class="math">\(Q\)</span>, one is <a href="https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process">Gramm-Schmidt Process</a>, 
second is <a href="https://en.wikipedia.org/wiki/Householder_transformation">Householder Transformation</a>, 
and third is <a href="https://en.wikipedia.org/wiki/Givens_rotation">Givens Rotation</a>. These methods are out of the scope of this blog 
post series and hence I'm going to explain all of them in separate blog posts. Consequently, there is no calculation besides python code in numerical representation section.</p>
<h3 id="eigendecomposition">Eigendecomposition<a class="headerlink" href="#eigendecomposition" title="Permanent link">&para;</a></h3>
<p><a id="Eigendecomposition"></a></p>
<hr>
<p>Here is the question. What's the usage of eigenvalues and eigenvectors? Besides other usages, they help us to perform 
matrix decomposition and this decomposition is called eigendecomposition or spectral decomposition. In the case of the 
eigendecomposition, we decompose the initial matrix into the product of its eigenvectors and eigenvalues by the following formula:</p>
<div class="math">$$
A = Q \Lambda Q^{-1}
$$</div>
<p><span class="math">\(A\)</span> is <span class="math">\(n\times n\)</span> square matrix, <span class="math">\(Q\)</span> is the matrix whose columns are the eigenvectors, which in turn are linearly 
independent and <span class="math">\(\Lambda\)</span> is diagonal matrix of eigenvalues of <span class="math">\(A\)</span> and these eigenvalues are not necessarily distinct.</p>
<p>To see the detailed steps of this decomposition, consider the aforementioned example of the matrix <span class="math">\(A\)</span> 
for which we already found eigenvalues and eigenvectors.</p>
<div class="math">$$
A =
\begin{bmatrix}
2 &amp; 0 &amp; 0 \\
0 &amp; 3 &amp; 4 \\
0 &amp; 4 &amp; 9
\end{bmatrix}
\quad
Q =
\begin{bmatrix}
0 &amp; 1 &amp; 0 \\
-2 &amp; 0 &amp; 1 \\
1 &amp; 0 &amp; 2
\end{bmatrix}
\quad
\Lambda = 
\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 2 &amp; 0 \\
0 &amp; 0 &amp; 11
\end{bmatrix}
\quad
Q^{-1} =
\begin{bmatrix}
0 &amp; -0.4 &amp; 0.2 \\
1 &amp; 0 &amp; 0 \\
0 &amp; 0.2 &amp; 0.4
\end{bmatrix}
$$</div>
<p>We have all the matrices and now take matrix multiplication according to the above formula. Particularly, 
multiply <span class="math">\(Q\)</span> by <span class="math">\(\Lambda\)</span> and by <span class="math">\(Q^{-1}\)</span>. We have to get original matrix <span class="math">\(A\)</span></p>
<p>Furthermore, if matrix <span class="math">\(A\)</span> is a real symmetric matrix, then eigendecomposition can be performed by the following formula:</p>
<div class="math">$$
A = Q \Lambda Q^{T}
$$</div>
<p>The only difference between this formula and above formula is that the matrix <span class="math">\(A\)</span> is <span class="math">\(n\times n\)</span> real symmetric square 
matrix and instead of taking the inverse of eigenvector matrix we take the transpose of it. Moreover, for a real 
symmetric matrix, eigenvectors corresponding to different eigenvalues are orthogonal. Consider the following example:</p>
<div class="math">$$
A =
\begin{bmatrix}
6 &amp; 2 \\
2 &amp; 3
\end{bmatrix}
$$</div>
<p>The matrix is symmetric because of the original matrix equal to its transpose, <span class="math">\(A = A^{T}\)</span></p>
<p>Its eigenvalues are <span class="math">\(\lambda_{1} = 7\)</span> and <span class="math">\(\lambda_{2} = 2\)</span> and corresponding eigenvectors are </p>
<div class="math">$$
v_{\lambda_{1}} =
\begin{bmatrix}
0.89442719 \\
0.4472136
\end{bmatrix}
\quad
v_{\lambda_{2}} =
\begin{bmatrix}
-0.4472136 \\
0.89442719
\end{bmatrix}
$$</div>
<p>And in this set up, matrices <span class="math">\(Q\)</span>, <span class="math">\(\Lambda\)</span> and <span class="math">\(Q^{T}\)</span> are the following:</p>
<div class="math">$$
Q =
\begin{bmatrix}
0.89442719 &amp; -0.4472136 \\
0.4472136 &amp; 0.89442719 \\
\end{bmatrix}
\quad
\Lambda = 
\begin{bmatrix}
7 &amp; 0 \\
0 &amp; 2 \\
\end{bmatrix}
\quad
Q^{T} =
\begin{bmatrix}
0.89442719 &amp; 0.4472136 \\
-0.4472136 &amp; 0.89442719 \\
\end{bmatrix}
$$</div>
<p>Taking matrix product gives initial matrix <span class="math">\(A\)</span>.</p>
<p>To verify all of this calculation see Python code below.</p>
<p><strong>Eigendecomposition cannot be used for non-square matrices. Below, we will see the Singular Value Decomposition (SVD) which is another way of decomposing matrices. The advantage of the SVD is that you can use it also with non-square matrices.</strong></p>
<h3 id="singular-value-decomposition">Singular Value Decomposition<a class="headerlink" href="#singular-value-decomposition" title="Permanent link">&para;</a></h3>
<p><a id="Singular_Value_Decomposition"></a></p>
<hr>
<p>Singular Value Decomposition (SVD) is another way of matrix factorization. It is the generalization of the eigendecomposition. 
In this context, generalization means that eigendecomposition is applicable only for square <span class="math">\(n \times n\)</span> matrices, 
while Singular Value Decomposition (SVD) is applicable for any <span class="math">\(m \times n\)</span> matrices.</p>
<p>SVD for a <span class="math">\(m \times n\)</span> matrix <span class="math">\(A\)</span> is computed by the following formula:</p>
<div class="math">$$
A = U \ D \ V^{T}
$$</div>
<p>Where, <span class="math">\(U\)</span>'s columns are <em>left singular vectors</em> of <span class="math">\(A\)</span>, <span class="math">\(V\)</span>'s columns are <em>right singular vectors</em> of <span class="math">\(A\)</span> and <span class="math">\(D\)</span>  is a 
diagonal matrix, not necessarily square matrix, containing <strong>singular values</strong> of <span class="math">\(A\)</span> on main diagonal. 
Singular values of <span class="math">\(m \times n\)</span> matrix <span class="math">\(A\)</span> are the <strong>square roots of the eigenvalues</strong> of <span class="math">\(A^{T}A\)</span>, which is a square matrix. 
If our initial matrix <span class="math">\(A\)</span> is square or <span class="math">\(n \times n\)</span> then singular values <strong>coincide</strong> eigenvalues. 
Moreover, all of these defines the path towards eigendecomposition. Let see how this path is defined.</p>
<p>Matrices, <span class="math">\(U\)</span>, <span class="math">\(D\)</span>, and <span class="math">\(V\)</span> can be found by transforming <span class="math">\(A\)</span> into a square matrix and computing eigenvalues and 
eigenvectors of this transformed matrix. This transformation is done by multiplying <span class="math">\(A\)</span> by its transpose <span class="math">\(A^{T}\)</span>. 
After that, matrices <span class="math">\(U\)</span>, <span class="math">\(D\)</span> and <span class="math">\(V\)</span> are the following:</p>
<ul>
<li>
<p><span class="math">\(U\)</span> corresponds to the eigenvectors of <span class="math">\(AA^{T}\)</span></p>
</li>
<li>
<p><span class="math">\(V\)</span> corresponds to eigenvectors of <span class="math">\(A^{T}A\)</span></p>
</li>
<li>
<p><span class="math">\(D\)</span> corresponds to eigenvalues, either <span class="math">\(AA^{T}\)</span> or <span class="math">\(A^{T}A\)</span>, which are the same</p>
</li>
</ul>
<p>Theory almost always seems confusing. Consider a numerical example and Python code below for clarification.</p>
<p>Let our initial matrix <span class="math">\(A\)</span> be:</p>
<div class="math">$$
A =
\begin{bmatrix}
0 &amp; 1 &amp; 0 \\
\sqrt{2} &amp; 2 &amp; 0 \\
0 &amp; 1 &amp; 1
\end{bmatrix}
$$</div>
<p>Here, to use SVD first we need to find <span class="math">\(AA^{T}\)</span> and <span class="math">\(A^{T}A\)</span>.</p>
<div class="math">$$
AA^{T} =
\begin{bmatrix}
2 &amp; 2 &amp; 2 \\
2 &amp; 6 &amp; 2 \\
2 &amp; 2 &amp; 2
\end{bmatrix}
\quad
A^{T}A =
\begin{bmatrix}
2 &amp; 2\sqrt{2} &amp; 0 \\
2\sqrt{2} &amp; 6 &amp; 2 \\
0 &amp; 2 &amp; 2
\end{bmatrix}
$$</div>
<p>In the next step, we have to find eigenvalues and eigenvectors for <span class="math">\(AA^{T}\)</span> and <span class="math">\(A^{T}A\)</span>. The characteristic polynomial is</p>
<div class="math">$$
-\lambda^{3} + 10\lambda^2 - 16\lambda
$$</div>
<p>with roots equal to <span class="math">\(\lambda_{1} = 8\)</span>, <span class="math">\(\lambda_{2} = 2\)</span>, and <span class="math">\(\lambda_{3} = 0\)</span>. Note that these eigenvalues are 
the same for the <span class="math">\(A^{T}A\)</span>. We need singular values which are square root from eigenvalues. 
Let denote them by <span class="math">\(\sigma\)</span> such as <span class="math">\(\sigma_{1} = \sqrt{8} = 2\sqrt{2}\)</span>, <span class="math">\(\sigma_{2} = \sqrt{2}\)</span> and <span class="math">\(\sigma_{3} = \sqrt{0} = 0\)</span>. 
We now can construct diagonal matrix of singular values:</p>
<div class="math">$$
D =
\begin{bmatrix}
2\sqrt{2} &amp; 0 &amp; 0 \\
0 &amp; \sqrt{2} &amp; 0 \\
0 &amp; 0 &amp; 0
\end{bmatrix}
$$</div>
<p>Now we have to find matrices <span class="math">\(U\)</span> and <span class="math">\(V\)</span>. We have everything what we need. First find eigenvectors 
of <span class="math">\(AA^{T}\)</span> for <span class="math">\(\lambda_{1} = 8\)</span>, <span class="math">\(\lambda_{2} = 2\)</span>, and <span class="math">\(\lambda_{3} = 0\)</span>, which are the following:</p>
<div class="math">$$
U_{1} =
\begin{bmatrix}
\frac{1}{\sqrt{6}}\\
\frac{2}{\sqrt{6}} \\
\frac{1}{\sqrt{6}}
\end{bmatrix}
\quad
U_{2} =
\begin{bmatrix}
-\frac{1}{\sqrt{3}}\\
\frac{1}{\sqrt{3}} \\
-\frac{1}{\sqrt{3}}
\end{bmatrix}
\quad
U_{3} =
\begin{bmatrix}
\frac{1}{\sqrt{2}}\\
0 \\
-\frac{1}{\sqrt{2}}
\end{bmatrix}
$$</div>
<p>Note that eigenvectors are normalized.</p>
<p>As we have eigenvectors, our <span class="math">\(U\)</span> matrix is:</p>
<div class="math">$$
U =
\begin{bmatrix}
\frac{1}{\sqrt{6}} &amp; -\frac{1}{\sqrt{3}} &amp; \frac{1}{\sqrt{2}}\\
\frac{2}{\sqrt{6}} &amp; \frac{1}{\sqrt{3}} &amp; 0 \\
\frac{1}{\sqrt{6}} &amp; -\frac{1}{\sqrt{3}} &amp; -\frac{1}{\sqrt{2}}
\end{bmatrix}
$$</div>
<p>In the same fashion, we can find matrix <span class="math">\(V\)</span>, which is:</p>
<div class="math">$$
V =
\begin{bmatrix}
\frac{1}{\sqrt{6}} &amp; \frac{1}{\sqrt{3}} &amp; \frac{1}{\sqrt{2}}\\
\frac{3}{\sqrt{12}} &amp; 0 &amp; -\frac{1}{2} \\
\frac{1}{\sqrt{12}} &amp; -\frac{2}{\sqrt{6}} &amp; \frac{1}{2}
\end{bmatrix}
$$</div>
<p>According to the formula we have</p>
<div class="math">$$
A = U \ D \ V^{T} =
\begin{bmatrix}
\frac{1}{\sqrt{6}} &amp; -\frac{1}{\sqrt{3}} &amp; \frac{1}{\sqrt{2}}\\
\frac{2}{\sqrt{6}} &amp; \frac{1}{\sqrt{3}} &amp; 0 \\
\frac{1}{\sqrt{6}} &amp; -\frac{1}{\sqrt{3}} &amp; -\frac{1}{\sqrt{2}}
\end{bmatrix}
\cdot
\begin{bmatrix}
2\sqrt{2} &amp; 0 &amp; 0 \\
0 &amp; \sqrt{2} &amp; 0 \\
0 &amp; 0 &amp; 0
\end{bmatrix}
\cdot
\begin{bmatrix}
\frac{1}{\sqrt{6}} &amp; \frac{1}{\sqrt{3}} &amp; \frac{1}{\sqrt{2}}\\
\frac{3}{\sqrt{12}} &amp; 0 &amp; -\frac{1}{2} \\
\frac{1}{\sqrt{12}} &amp; -\frac{2}{\sqrt{6}} &amp; \frac{1}{2}
\end{bmatrix}
^{T} = A
$$</div>
<h3 id="inverse-of-a-square-full-rank-matrix">Inverse of a Square Full Rank Matrix<a class="headerlink" href="#inverse-of-a-square-full-rank-matrix" title="Permanent link">&para;</a></h3>
<p><a id="Inverse_of_a_Square_Full_Rank_Matrix"></a></p>
<hr>
<p>Here, I want to present one more way to find the inverse of a matrix and show you one more usage of eigendecomposition. 
Let's get started. If a matrix <span class="math">\(A\)</span> can be eigendecomposed and it has no any eigenvalue equal to zero, 
then this matrix has the inverse and this inverse is given by:</p>
<div class="math">$$
A^{-1} =
Q \Lambda^{-1} Q^{-1}
$$</div>
<p>Matrices, <span class="math">\(Q\)</span>, and <span class="math">\(\Lambda\)</span> are already known for us. Consider an example:</p>
<div class="math">$$
A =
\begin{bmatrix}
1 &amp; 2 \\
4 &amp; 3
\end{bmatrix}
$$</div>
<p>Its eigenvalues are <span class="math">\(\lambda_{1} = -1\)</span> and <span class="math">\(\lambda_{2} = 5\)</span> and eigenvectors are:</p>
<div class="math">$$
v_{\lambda_{1}} =
\begin{bmatrix}
-0.70710678 \\
0.70710678
\end{bmatrix}
\quad
v_{\lambda_{2}} =
\begin{bmatrix}
0.4472136 \\
-0.89442719
\end{bmatrix}
$$</div>
<p>Let calculate the inverse of <span class="math">\(A\)</span></p>
<div class="math">$$
A^{-1} = Q \Lambda^{-1} Q^{-1} =
\begin{bmatrix}
-0.70710678 &amp; -0.4472136 \\
0.70710678 &amp; -0.89442719
\end{bmatrix}
\cdot
\begin{bmatrix}
-1 &amp; -0 \\
0 &amp; 0.2
\end{bmatrix}
\cdot
\begin{bmatrix}
-0.94280904 &amp; 0.47140452 \\
-0.74535599 &amp; -0.74535599
\end{bmatrix} =
\begin{bmatrix}
-0.6 &amp; 0.4 \\
0.8 &amp; -0.2
\end{bmatrix}
$$</div>
<h3 id="numerical-representation">Numerical Representation<a class="headerlink" href="#numerical-representation" title="Permanent link">&para;</a></h3>
<p><a id="Numerical_Representation_Decompositions"></a></p>
<h4 id="cholesky-decomposition_1">Cholesky Decomposition<a class="headerlink" href="#cholesky-decomposition_1" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">25</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="o">-</span><span class="mi">5</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">15</span><span class="p">,</span><span class="mi">18</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
              <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">11</span><span class="p">]])</span>


<span class="c1"># Cholesky decomposition, find lower triangular matrix L</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="c1"># Take transpose</span>
<span class="n">L_T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>


<span class="c1"># Check if it&#39;s correct</span>
<span class="n">A</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">L_T</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">array([[ True,  True,  True],</span>
<span class="err">       [ True,  True,  True],</span>
<span class="err">       [ True,  True,  True]])</span>
</pre></div>


<h4 id="qr-decomposition_1">QR Decomposition<a class="headerlink" href="#qr-decomposition_1" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">12</span><span class="p">,</span><span class="o">-</span><span class="mi">51</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="mi">167</span><span class="p">,</span><span class="o">-</span><span class="mi">68</span><span class="p">],</span>
              <span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="o">-</span><span class="mi">41</span><span class="p">]])</span>


<span class="c1"># QR decomposition</span>
<span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Q =&quot;</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R =&quot;</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A = QR&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span><span class="n">R</span><span class="p">),</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">Q</span> <span class="o">=</span>
<span class="p">[[</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">85714286</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">39428571</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">33142857</span><span class="p">]</span>
 <span class="p">[</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">42857143</span> <span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">90285714</span> <span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">03428571</span><span class="p">]</span>
 <span class="p">[</span> <span class="mi">0</span><span class="p">.</span><span class="mi">28571429</span> <span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">17142857</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">94285714</span><span class="p">]]</span>

<span class="n">R</span> <span class="o">=</span>
<span class="p">[[</span> <span class="o">-</span><span class="mi">14</span><span class="p">.</span>  <span class="o">-</span><span class="mi">21</span><span class="p">.</span>   <span class="mi">14</span><span class="p">.]</span>
 <span class="p">[</span>   <span class="mi">0</span><span class="p">.</span> <span class="o">-</span><span class="mi">175</span><span class="p">.</span>   <span class="mi">70</span><span class="p">.]</span>
 <span class="p">[</span>   <span class="mi">0</span><span class="p">.</span>    <span class="mi">0</span><span class="p">.</span>  <span class="o">-</span><span class="mi">35</span><span class="p">.]]</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">QR</span>
<span class="p">[[</span> <span class="mi">12</span><span class="p">.</span> <span class="o">-</span><span class="mi">51</span><span class="p">.</span>   <span class="mi">4</span><span class="p">.]</span>
 <span class="p">[</span>  <span class="mi">6</span><span class="p">.</span> <span class="mi">167</span><span class="p">.</span> <span class="o">-</span><span class="mi">68</span><span class="p">.]</span>
 <span class="p">[</span> <span class="o">-</span><span class="mi">4</span><span class="p">.</span>  <span class="mi">24</span><span class="p">.</span> <span class="o">-</span><span class="mi">41</span><span class="p">.]]</span>
</pre></div>


<h4 id="eigendecomposition_1">Eigendecomposition<a class="headerlink" href="#eigendecomposition_1" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="c1"># Eigendecomposition for non-symmetric matrix</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">9</span><span class="p">]])</span>


<span class="n">eigenvalues1</span><span class="p">,</span> <span class="n">eigenvectors1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>


<span class="c1"># Form diagonal matrix from eigenvalues</span>
<span class="n">L1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">eigenvalues1</span><span class="p">)</span>


<span class="c1"># Separate eigenvector matrix and take its inverse</span>
<span class="n">Q1</span> <span class="o">=</span> <span class="n">eigenvectors1</span>
<span class="n">inv_Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Q1</span><span class="p">)</span>


<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q1</span><span class="p">,</span><span class="n">L1</span><span class="p">),</span><span class="n">inv_Q</span><span class="p">)</span>


<span class="c1"># Check if B equal to A</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Decomposed matrix B:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>


<span class="c1"># Numpy produces normalized eigenvectors and don&#39;t be confused with my calculations above</span>




<span class="c1"># Eigendecomposition for symmetric matrix</span>

<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">6</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]])</span>

<span class="n">eigenvalues2</span><span class="p">,</span> <span class="n">eigenvectors2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>

<span class="c1"># Eigenvalues</span>
<span class="n">L2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">eigenvalues2</span><span class="p">)</span>

<span class="c1"># Eigenvectors</span>
<span class="n">Q2</span> <span class="o">=</span> <span class="n">eigenvectors2</span>
<span class="n">Q2_T</span> <span class="o">=</span> <span class="n">Q2</span><span class="o">.</span><span class="n">T</span>


<span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q2</span><span class="p">,</span><span class="n">L2</span><span class="p">),</span><span class="n">Q2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>


<span class="c1"># Check if D equal to C</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Decomposed matrix D:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">Decomposed</span> <span class="n">matrix</span> <span class="n">B</span><span class="p">:</span>
<span class="p">[[</span><span class="mi">2</span><span class="p">.</span> <span class="mi">0</span><span class="p">.</span> <span class="mi">0</span><span class="p">.]</span>
 <span class="p">[</span><span class="mi">0</span><span class="p">.</span> <span class="mi">3</span><span class="p">.</span> <span class="mi">4</span><span class="p">.]</span>
 <span class="p">[</span><span class="mi">0</span><span class="p">.</span> <span class="mi">4</span><span class="p">.</span> <span class="mi">9</span><span class="p">.]]</span>

<span class="n">Decomposed</span> <span class="n">matrix</span> <span class="n">D</span><span class="p">:</span>
<span class="p">[[</span><span class="mi">6</span><span class="p">.</span> <span class="mi">2</span><span class="p">.]</span>
 <span class="p">[</span><span class="mi">2</span><span class="p">.</span> <span class="mi">3</span><span class="p">.]]</span>
</pre></div>


<h4 id="singular-value-decomposition_1">Singular Value Decomposition<a class="headerlink" href="#singular-value-decomposition_1" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># Suppress scientific notation</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
              <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>


<span class="n">U</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;U =&quot;</span><span class="p">,</span> <span class="n">U</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;D =&quot;</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;V =&quot;</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>

<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">D</span><span class="p">),</span> <span class="n">V</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;B =&quot;</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">U</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">32099833</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">14524317</span> <span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">93587632</span><span class="p">]</span>
 <span class="p">[</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">87192053</span> <span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">43111301</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">23215547</span><span class="p">]</span>
 <span class="p">[</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">36974946</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">8905313</span>   <span class="mi">0</span><span class="p">.</span><span class="mi">26502706</span><span class="p">]]</span>

<span class="n">D</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">.</span><span class="mi">75398408</span> <span class="mi">1</span><span class="p">.</span><span class="mi">09310654</span> <span class="mi">0</span><span class="p">.</span><span class="mi">46977627</span><span class="p">]</span>

<span class="n">V</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">44774472</span> <span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">8840243</span>  <span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">13425984</span><span class="p">]</span>
 <span class="p">[</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">55775521</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">15876626</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">81467932</span><span class="p">]</span>
 <span class="p">[</span> <span class="mi">0</span><span class="p">.</span><span class="mi">69888038</span> <span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">43965249</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">56415592</span><span class="p">]]</span>

<span class="n">B</span> <span class="o">=</span> <span class="p">[[</span> <span class="mi">0</span><span class="p">.</span>          <span class="mi">1</span><span class="p">.</span>         <span class="o">-</span><span class="mi">0</span><span class="p">.</span>        <span class="p">]</span>
 <span class="p">[</span> <span class="mi">1</span><span class="p">.</span><span class="mi">41421356</span>  <span class="mi">2</span><span class="p">.</span>          <span class="mi">0</span><span class="p">.</span>        <span class="p">]</span>
 <span class="p">[</span> <span class="mi">0</span><span class="p">.</span>          <span class="mi">1</span><span class="p">.</span>          <span class="mi">1</span><span class="p">.</span>        <span class="p">]]</span>
</pre></div>


<h4 id="inverse-of-a-square-full-rank-matrix_1">Inverse of a Square Full Rank Matrix<a class="headerlink" href="#inverse-of-a-square-full-rank-matrix_1" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">]])</span>


<span class="c1"># Eigenvalues and Eigenvectors</span>
<span class="n">L</span><span class="p">,</span> <span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="c1"># Diagonal eigenvalues</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
<span class="c1"># Inverse</span>
<span class="n">inv_L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>

<span class="c1"># Inverse of igenvector matrix</span>
<span class="n">inv_Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>


<span class="c1"># Calculate the inverse of A</span>
<span class="n">inv_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">inv_L</span><span class="p">,</span><span class="n">inv_Q</span><span class="p">))</span>

<span class="c1"># Print the inverse</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The inverse of A is&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inv_A</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">The inverse of A is</span>
<span class="err">[[-0.6  0.4]</span>
<span class="err"> [ 0.8 -0.2]]</span>
</pre></div>


<h2 id="conclusion">Conclusion<a class="headerlink" href="#conclusion" title="Permanent link">&para;</a></h2>
<p><a id="Conclusion"></a></p>
<hr>
<p>In conclusion, my aim was to make linear algebra tutorials which are in absence, while learning machine learning or deep learning. 
Particularly, existing materials either are pure mathematics books which cover lots of unnecessary(actually they are necessary) 
things or machine learning books which assume that you already have some linear algebra knowledge. The series starts 
from very basic and at the end explains some advanced topics. I can say that I tried my best to filter the materials 
and only explained the most relevant linear algebra topics for machine learning and deep learning.</p>
<p>Based on my experience, these tutorials are not enough to master the concepts and all intuitions but the journey should 
be continuous. Meaning, that you have to practice more and more.</p>
<h3 id="references">References<a class="headerlink" href="#references" title="Permanent link">&para;</a></h3>
<p><a id="References"></a></p>
<h4 id="matrix-decomposition">Matrix Decomposition<a class="headerlink" href="#matrix-decomposition" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><a href="https://rosettacode.org/wiki/Cholesky_decomposition">Cholesky Decomposition</a></p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Matrix_decomposition">Matrix Decomposition</a></p>
</li>
<li>
<p><a href="http://math.mit.edu/~gs/linearalgebra/">Introduction To Linear Algebra</a></p>
</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>


             


<div class="applause_button">
    <applause-button url=https://dsfabric.org/advances-of-linear-algebra-with-python-part-ii> </applause-button>
</div>

 
                <p id="post-share-links">
    Like this post? Share on:
      <a href="https://twitter.com/intent/tweet?text=Advances%20of%20Linear%20Algebra%20with%20Python%20-%20Part%20II&url=https%3A//dsfabric.org/advances-of-linear-algebra-with-python-part-ii&via=N_Okroshiashvil&hashtags=advance-linear-algebra,mathematics" target="_blank" rel="nofollow noopener noreferrer" title="Share on Twitter">Twitter</a>
 â       <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//dsfabric.org/advances-of-linear-algebra-with-python-part-ii" target="_blank" rel="nofollow noopener noreferrer" title="Share on Facebook">Facebook</a>
 â       <a href="mailto:?subject=Advances%20of%20Linear%20Algebra%20with%20Python%20-%20Part%20II&amp;body=https%3A//dsfabric.org/advances-of-linear-algebra-with-python-part-ii" target="_blank" rel="nofollow noopener noreferrer" title="Share via Email">Email</a>

            
            







<section>
    <h6 style="display:none;">Comments</h6>
    <p id="comment-message">So what do you think? Did I miss something? Is any part unclear? Leave your comments below. </p>

    <div class="accordion" id="accordion2">
        <div class="accordion-group">
            <div class="accordion-heading">
                <a class="accordion-toggle disqus-comment-count comment-count collapsed"
                   data-toggle="collapse"
                   data-parent="#accordion2"
                   data-disqus-identifier="https://dsfabric.org/advances-of-linear-algebra-with-python-part-ii"
                   href="https://dsfabric.org/advances-of-linear-algebra-with-python-part-ii#comment_thread"
                   id="comment-accordion-toggle">
                    Comments
                </a>
            </div>
            <div id="comment_thread" class="accordion-body collapse">
                <div class="accordion-inner">
                    <div class="comments">
                        <div id="disqus_thread"></div>
                        <script>
    var disqus_shortname = 'dsfabric';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());

    var disqus_identifier = 'https://dsfabric.org/advances-of-linear-algebra-with-python-part-ii';
    var disqus_url = 'https://dsfabric.org/advances-of-linear-algebra-with-python-part-ii';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>

<noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>




                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

            <hr/>
<section>
    <h2>Keep Reading</h2>
<ul class="related-posts-list">
<li><a href="https://dsfabric.org/advances-of-linear-algebra-with-python-part-i" title="Advances of Linear Algebra with Python - Part I">Advances of Linear Algebra with Python - Part I</a></li>
</ul>
<hr />
</section>
            <aside>
            <nav>
            <ul class="articles-timeline">
                <li class="previous-article">Â« <a href="https://dsfabric.org/advances-of-linear-algebra-with-python-part-i" title="Previous: Advances of Linear Algebra with Python - Part I">Advances of Linear Algebra with Python - Part I</a></li>
                <li class="next-article"><a href="https://dsfabric.org/simple-interactive-data-visualization-with-plotly-express" title="Next: Simple Interactive Data Visualization with Plotly Express">Simple Interactive Data Visualization with Plotly Express</a> Â»</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2019-03-05T12:14:00+04:00">á¡áá 05 ááá á¢á 2019</time>
            <h4>Category</h4>
            <a class="category-link" href="https://dsfabric.org/categories#mathematics-ref">Mathematics</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://dsfabric.org/tags#advance-linear-algebra-ref">Advance Linear Algebra
                    <span class="superscript">2</span>
</a></li>
                <li><a href="https://dsfabric.org/tags#mathematics-ref">Mathematics
</a></li>
            </ul>
<h4>Stay in Touch</h4>
<div id="sidebar-social-link">
    <a href="https://www.linkedin.com/in/nodar-okroshiashvili/" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="LinkedIn" role="img" viewBox="0 0 512 512" fill="#fff"><rect width="512" height="512" rx="15%" fill="#0077b5"/><circle cx="142" cy="138" r="37"/><path stroke="#fff" stroke-width="66" d="M244 194v198M142 194v198"/><path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg>
    </a>
    <a href="https://github.com/Okroshiashvili" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
    <a href="https://twitter.com/N_Okroshiashvil" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="Twitter" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1da1f3"/><path fill="#fff" d="M437 152a72 72 0 0 1-40 12 72 72 0 0 0 32-40 72 72 0 0 1-45 17 72 72 0 0 0-122 65 200 200 0 0 1-145-74 72 72 0 0 0 22 94 72 72 0 0 1-32-7 72 72 0 0 0 56 69 72 72 0 0 1-32 1 72 72 0 0 0 67 50 200 200 0 0 1-105 29 200 200 0 0 0 309-179 200 200 0 0 0 35-37"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>
    <div>
        Content licensed under <a rel="license nofollow noopener noreferrer"
    href="http://creativecommons.org/licenses/by/4.0/" target="_blank">
    Creative Commons Attribution 4.0 International License</a>.
    </div>

    <div>
        <span class="site-name">Data Science Fabric</span> - Torture the data, and it will confess to anything. Ronald Coase
    </div>



    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://dsfabric.org/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>